{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rasOe6jNJbFj",
        "colab_type": "text"
      },
      "source": [
        "# How to train a ResNet50 on RxRx1 using TPUs \n",
        "\n",
        "Colaboratory makes it easy to train models using [Cloud TPUs](https://cloud.google.com/tpu/), and this notebook demonstrates how to use the code in [rxrx1-utils](https://github.com/recursionpharma/rxrx1-utils) to train ResNet50 on the RxRx1 image set using Colab TPU.\n",
        "\n",
        "Be sure to select the TPU runtime before beginning!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKtZctcXJTAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNgr17uD0K--",
        "colab_type": "code",
        "outputId": "779d17e0-f75f-4ed5-87c3-f43e7ee24738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "if 'google.colab' in sys.modules:\n",
        "    !git clone https://github.com/recursionpharma/rxrx1-utils\n",
        "    sys.path.append('/content/rxrx1-utils')\n",
        "\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "    \n",
        "from rxrx.main import main"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'rxrx1-utils'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/54)   \u001b[K\rremote: Counting objects:   3% (2/54)   \u001b[K\rremote: Counting objects:   5% (3/54)   \u001b[K\rremote: Counting objects:   7% (4/54)   \u001b[K\rremote: Counting objects:   9% (5/54)   \u001b[K\rremote: Counting objects:  11% (6/54)   \u001b[K\rremote: Counting objects:  12% (7/54)   \u001b[K\rremote: Counting objects:  14% (8/54)   \u001b[K\rremote: Counting objects:  16% (9/54)   \u001b[K\rremote: Counting objects:  18% (10/54)   \u001b[K\rremote: Counting objects:  20% (11/54)   \u001b[K\rremote: Counting objects:  22% (12/54)   \u001b[K\rremote: Counting objects:  24% (13/54)   \u001b[K\rremote: Counting objects:  25% (14/54)   \u001b[K\rremote: Counting objects:  27% (15/54)   \u001b[K\rremote: Counting objects:  29% (16/54)   \u001b[K\rremote: Counting objects:  31% (17/54)   \u001b[K\rremote: Counting objects:  33% (18/54)   \u001b[K\rremote: Counting objects:  35% (19/54)   \u001b[K\rremote: Counting objects:  37% (20/54)   \u001b[K\rremote: Counting objects:  38% (21/54)   \u001b[K\rremote: Counting objects:  40% (22/54)   \u001b[K\rremote: Counting objects:  42% (23/54)   \u001b[K\rremote: Counting objects:  44% (24/54)   \u001b[K\rremote: Counting objects:  46% (25/54)   \u001b[K\rremote: Counting objects:  48% (26/54)   \u001b[K\rremote: Counting objects:  50% (27/54)   \u001b[K\rremote: Counting objects:  51% (28/54)   \u001b[K\rremote: Counting objects:  53% (29/54)   \u001b[K\rremote: Counting objects:  55% (30/54)   \u001b[K\rremote: Counting objects:  57% (31/54)   \u001b[K\rremote: Counting objects:  59% (32/54)   \u001b[K\rremote: Counting objects:  61% (33/54)   \u001b[K\rremote: Counting objects:  62% (34/54)   \u001b[K\rremote: Counting objects:  64% (35/54)   \u001b[K\rremote: Counting objects:  66% (36/54)   \u001b[K\rremote: Counting objects:  68% (37/54)   \u001b[K\rremote: Counting objects:  70% (38/54)   \u001b[K\rremote: Counting objects:  72% (39/54)   \u001b[K\rremote: Counting objects:  74% (40/54)   \u001b[K\rremote: Counting objects:  75% (41/54)   \u001b[K\rremote: Counting objects:  77% (42/54)   \u001b[K\rremote: Counting objects:  79% (43/54)   \u001b[K\rremote: Counting objects:  81% (44/54)   \u001b[K\rremote: Counting objects:  83% (45/54)   \u001b[K\rremote: Counting objects:  85% (46/54)   \u001b[K\rremote: Counting objects:  87% (47/54)   \u001b[K\rremote: Counting objects:  88% (48/54)   \u001b[K\rremote: Counting objects:  90% (49/54)   \u001b[K\rremote: Counting objects:  92% (50/54)   \u001b[K\rremote: Counting objects:  94% (51/54)   \u001b[K\rremote: Counting objects:  96% (52/54)   \u001b[K\rremote: Counting objects:  98% (53/54)   \u001b[K\rremote: Counting objects: 100% (54/54)   \u001b[K\rremote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 54 (delta 20), reused 46 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (54/54), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HrPeVFofzIdy"
      },
      "source": [
        "## Train\n",
        "\n",
        "Set `MODEL_DIR` to be a Google Cloud Storage bucket that you can write to.   The code will write your checkpoins to this directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9MjRJpwJTAw",
        "colab_type": "code",
        "outputId": "38a9bb51-5a7a-4f6d-9661-723ea704e0ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "MODEL_DIR = 'gs://path/to/your/bucket'\n",
        "URL_BASE_PATH = 'gs://rxrx1-us-central1/tfrecords/random-42'\n",
        "\n",
        "# make sure we're in a TPU runtime\n",
        "assert 'COLAB_TPU_ADDR' in os.environ\n",
        "\n",
        "# set TPU-relevant args\n",
        "tpu_grpc = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "num_shards = 8  # colab uses Cloud TPU v2-8\n",
        "\n",
        "# upload credentials to the TPU\n",
        "with tf.Session(tpu_grpc) as sess:\n",
        "    data = json.load(open('/content/adc.json'))\n",
        "    tf.contrib.cloud.configure_gcs(sess, credentials=data)\n",
        "\n",
        "main(use_tpu=True,\n",
        "     tpu=tpu_grpc,\n",
        "     gcp_project=None,\n",
        "     tpu_zone=None,\n",
        "     url_base_path=URL_BASE_PATH,\n",
        "     use_cache=False,\n",
        "     model_dir=MODEL_DIR,\n",
        "     train_epochs=3,\n",
        "     train_batch_size=512,\n",
        "     num_train_images=73030,\n",
        "     epochs_per_loop=1,\n",
        "     log_step_count_epochs=1,\n",
        "     num_cores=num_shards,\n",
        "     data_format='channels_last',\n",
        "     transpose_input=True,\n",
        "     tf_precision='bfloat16',\n",
        "     n_classes=1108,\n",
        "     momentum=0.9,\n",
        "     weight_decay=1e-4,\n",
        "     base_learning_rate=0.2,\n",
        "     warmup_epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0627 00:50:41.234449 140143222630272 estimator.py:1984] Estimator's model_fn (functools.partial(<function resnet_model_fn at 0x7f756b216950>, n_classes=1108, num_train_images=73030, data_format='channels_last', transpose_input=True, train_batch_size=512, iterations_per_loop=142, tf_precision='bfloat16', momentum=0.9, weight_decay=0.0001, base_learning_rate=0.2, warmup_epochs=5, model_dir='gs://recursion-tpu-training/berton/rxrx1_test/my_test_3', use_tpu=True, resnet_depth=50)) includes params argument, but params are not passed to Estimator.\n",
            "W0627 00:50:41.382101 140143222630272 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0627 00:50:41.424432 140143222630272 deprecation.py:323] From /content/rxrx1-utils/rxrx/input.py:94: shuffle_and_repeat (from tensorflow.contrib.data.python.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.shuffle_and_repeat(...)`.\n",
            "W0627 00:50:41.425866 140143222630272 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/shuffle_ops.py:54: shuffle_and_repeat (from tensorflow.python.data.experimental.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.shuffle(buffer_size, seed)` followed by `tf.data.Dataset.repeat(count)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0627 00:50:41.436912 140143222630272 deprecation.py:323] From /content/rxrx1-utils/rxrx/input.py:115: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0627 00:50:41.438162 140143222630272 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0627 00:50:41.474455 140143222630272 deprecation.py:323] From /content/rxrx1-utils/rxrx/input.py:125: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0627 00:50:41.475806 140143222630272 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0627 00:50:41.483877 140143222630272 deprecation_wrapper.py:119] From /content/rxrx1-utils/rxrx/input.py:48: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0627 00:50:41.485905 140143222630272 deprecation_wrapper.py:119] From /content/rxrx1-utils/rxrx/input.py:59: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0627 00:50:41.596268 140143222630272 deprecation.py:323] From /content/rxrx1-utils/rxrx/official_resnet.py:211: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "W0627 00:50:41.851608 140143222630272 deprecation.py:323] From /content/rxrx1-utils/rxrx/official_resnet.py:70: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
            "W0627 00:50:41.960987 140143222630272 deprecation.py:323] From /content/rxrx1-utils/rxrx/official_resnet.py:413: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n",
            "W0627 00:50:46.138833 140143222630272 deprecation.py:323] From /content/rxrx1-utils/rxrx/official_resnet.py:442: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.AveragePooling2D instead.\n",
            "W0627 00:50:46.147887 140143222630272 deprecation.py:323] From /content/rxrx1-utils/rxrx/official_resnet.py:449: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0627 00:50:46.688333 140143222630272 deprecation_wrapper.py:119] From /content/rxrx1-utils/rxrx/main.py:125: The name tf.losses.softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.softmax_cross_entropy instead.\n",
            "\n",
            "W0627 00:50:46.738123 140143222630272 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0627 00:50:46.757446 140143222630272 deprecation_wrapper.py:119] From /content/rxrx1-utils/rxrx/main.py:131: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0627 00:50:46.860217 140143222630272 deprecation_wrapper.py:119] From /content/rxrx1-utils/rxrx/main.py:138: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
            "\n",
            "W0627 00:50:46.872241 140143222630272 deprecation_wrapper.py:119] From /content/rxrx1-utils/rxrx/main.py:145: The name tf.train.cosine_decay_restarts is deprecated. Please use tf.compat.v1.train.cosine_decay_restarts instead.\n",
            "\n",
            "W0627 00:50:46.921439 140143222630272 deprecation_wrapper.py:119] From /content/rxrx1-utils/rxrx/main.py:155: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "W0627 00:50:46.923054 140143222630272 deprecation_wrapper.py:119] From /content/rxrx1-utils/rxrx/main.py:167: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "W0627 00:50:46.924323 140143222630272 deprecation_wrapper.py:119] From /content/rxrx1-utils/rxrx/main.py:167: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0627 00:51:28.001146 140143222630272 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:741: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}